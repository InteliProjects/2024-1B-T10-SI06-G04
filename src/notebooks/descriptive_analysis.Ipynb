{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiente de Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir variáveis do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "isAtGoogleColab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install seaborn\n",
    "%pip install matplotlib.pyplot\n",
    "%pip install numpy\n",
    "%pip install nltk\n",
    "%pip install install openpyxl\n",
    "%pip install spacy\n",
    "%pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixando dados do spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "spacy.cli.download('pt_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/classification-labeled.csv', encoding='latin1', delimiter=';', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Descritiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar as palavras dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contando os caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df[\"qt_char\"] = df['comment'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contando as palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estatísticas gerais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Removes stopwords, punctuation, and spaces from the input text using spaCy.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    filtered_sentence = [token.text for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "data['processed_comment'] = data['comment'].apply(remove_stopwords)\n",
    "\n",
    "\"\"\"\n",
    "Finds the ten most common words in the processed comments.\n",
    "\"\"\"\n",
    "all_words = \" \".join(data['processed_comment']).split()\n",
    "common_words_counts = Counter(all_words).most_common(10)\n",
    "\n",
    "\"\"\"\n",
    "Prepares data for a bubble chart by calculating the average word count, median sentiment,\n",
    "and frequency for each of the ten most common words.\n",
    "\"\"\"\n",
    "word_details = []\n",
    "for word, count in common_words_counts:\n",
    "    temp_data = data[data['comment'].str.contains(word, case=False, regex=False)]\n",
    "    avg_word_count = temp_data['comment'].apply(lambda x: len(x.split())).mean()\n",
    "    median_sentiment = temp_data['sentiment'].median()\n",
    "    frequency = temp_data.shape[0]\n",
    "    word_details.append({'word': word, 'avg_word_count': avg_word_count, 'median_sentiment': median_sentiment, 'frequency': frequency})\n",
    "\n",
    "word_df = pd.DataFrame(word_details)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "palette = sns.color_palette(\"hsv\", n_colors=len(word_df['word']))\n",
    "bubble = sns.scatterplot(data=word_df, x='avg_word_count', y='median_sentiment', size='frequency', sizes=(100, 2000), hue='word', alpha=0.7, palette=palette)\n",
    "\n",
    "\"\"\"\n",
    "Adjusts text labels and customizes the legends to avoid overlapping and provide clear visualization.\n",
    "Includes separate legends for circle sizes explaining their representation.\n",
    "\"\"\"\n",
    "for i, row in word_df.iterrows():\n",
    "    plt.annotate(f\"{row['word']} ({row['frequency']})\",\n",
    "                 xy=(row['avg_word_count'], row['median_sentiment']),\n",
    "                 xytext=(row['avg_word_count'] + np.random.uniform(0.5, 1.5), row['median_sentiment'] + np.random.uniform(-0.05, 0.05)),\n",
    "                 textcoords=\"data\",\n",
    "                 ha='right', va='center',\n",
    "                 arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\", color='gray', lw=0.5))\n",
    "\n",
    "handles, labels = bubble.get_legend_handles_labels()\n",
    "plt.legend(handles=handles, labels=labels, title=\"Words\", loc='upper right', bbox_to_anchor=(1.25, 1))\n",
    "\n",
    "legend_elements = [Patch(facecolor='grey', edgecolor='grey',\n",
    "                         label='Circle size represents frequency of word usage')]\n",
    "plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.25, 0.85))\n",
    "\n",
    "plt.title('Improved Bubble Chart of Word Frequency, Average Comment Length, and Median Sentiment')\n",
    "plt.xlabel('Average Number of Words')\n",
    "plt.ylabel('Median Sentiment')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico \"Improved Bubble Chart of Word Frequency, Average Comment Length, and Median Sentiment\" utiliza a frequência de palavras, o comprimento médio dos comentários e o sentimento mediano para ilustrar como diferentes termos são utilizados nos comentários. Nele, termos como \"Uber\" destacam-se pela alta frequência e por aparecerem em comentários mais longos, sugerindo uma relevância ou interesse significativo. Palavras como \"lobbied\" e \"leak\" apresentam sentimentos predominantemente negativos, refletindo possíveis contextos críticos ou problemáticos. Este gráfico oferece uma visão clara de quais temas são mais discutidos ou controversos, ajudando na identificação de padrões importantes nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess the text by converting all comments to lowercase, removing all punctuation, and digits.\n",
    "\"\"\"\n",
    "data['comment'] = data['comment'].str.lower().str.replace('[^\\w\\s]', '', regex=True).str.replace('\\d+', '', regex=True)\n",
    "\n",
    "\"\"\"\n",
    "Define a set of stop words to be excluded from the analysis. This set can be updated based on specific requirements.\n",
    "\"\"\"\n",
    "stop_words = set(['and', 'the', 'uber', 'to', 'of', 'in', 'i', 'a', 'for', 'is', 'it', 'that', 'how', 'you'])\n",
    "\n",
    "def get_top_words(data, sentiment, top_n=10):\n",
    "    \"\"\"\n",
    "    Retrieves the top 'n' words for a given sentiment, excluding predefined stop words.\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame containing the comments and their associated sentiments.\n",
    "        sentiment (mixed): The sentiment category for which to retrieve top words.\n",
    "        top_n (int): Number of top words to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the most common words for the specified sentiment, excluding stop words.\n",
    "    \"\"\"\n",
    "    subset = data[data['sentiment'] == sentiment]\n",
    "    words = \" \".join(subset['comment']).split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return [word for word, count in Counter(filtered_words).most_common(top_n)]\n",
    "\n",
    "\"\"\"\n",
    "Prepare and collect the top words for each unique sentiment in the dataset for further analysis.\n",
    "\"\"\"\n",
    "sentiments = data['sentiment'].unique()\n",
    "top_words_by_sentiment = {sent: get_top_words(data, sent) for sent in sentiments}\n",
    "\n",
    "\"\"\"\n",
    "Calculate and compile data concerning the frequency of each top word across all sentiments.\n",
    "\"\"\"\n",
    "rows = []\n",
    "for sentiment, top_words in top_words_by_sentiment.items():\n",
    "    for word in top_words:\n",
    "        for sent in sentiments:\n",
    "            subset = data[data['sentiment'] == sent]\n",
    "            count = sum(subset['comment'].str.split().apply(lambda x: x.count(word)))\n",
    "            rows.append({'Word': word, 'Sentiment': sent, 'Frequency': count})\n",
    "\n",
    "\"\"\"\n",
    "Convert the compiled data into a DataFrame for visualization purposes.\n",
    "\"\"\"\n",
    "plot_data = pd.DataFrame(rows)\n",
    "\n",
    "def create_plot(plot_data, focus_sentiment):\n",
    "    \"\"\"\n",
    "    Generates a bar plot for word frequencies focused on a specific sentiment.\n",
    "    Args:\n",
    "        plot_data (DataFrame): DataFrame containing the words, their frequencies, and sentiments.\n",
    "        focus_sentiment (mixed): The sentiment to focus on for the plot.\n",
    "\n",
    "    Displays:\n",
    "        A bar plot visualizing the frequency of words focused on the specified sentiment.\n",
    "    \"\"\"\n",
    "    focused_words = top_words_by_sentiment[focus_sentiment]\n",
    "    focused_plot_data = plot_data[plot_data['Word'].isin(focused_words)]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Word', y='Frequency', hue='Sentiment', data=focused_plot_data, palette='viridis')\n",
    "    plt.title(f'Word Frequencies Focused on Sentiment {focus_sentiment} (Excluding Common Words)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Generate and display plots for each sentiment represented in the data.\n",
    "\"\"\"\n",
    "for sent in sentiments:\n",
    "    create_plot(plot_data, sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os gráficos mostram as frequências de palavras focadas em diferentes sentimentos após a remoção manual de stopwords comuns. Nos gráficos para sentimentos neutro e positivo, as palavras que emergem refletem aspectos mais específicos dos comentários, sem a interferência de termos gerais. Por exemplo, palavras como \"driver\" e \"eats\" são proeminentes em comentários positivos, apontando para tópicos específicos relacionados ao serviço. Já para o sentimento neutro, termos como \"have\" e \"but\" sugerem um contexto mais equilibrado ou discursivo. Essas análises ajudam a identificar quais aspectos dos serviços ou produtos estão recebendo atenção em diferentes tonalidades emocionais, permitindo uma compreensão mais precisa do feedback dos usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess the text by converting all comments to lowercase, removing punctuation, and digits.\n",
    "\"\"\"\n",
    "data['comment'] = data['comment'].str.lower().str.replace('[^\\w\\s]', '', regex=True).str.replace('\\d+', '', regex=True)\n",
    "\n",
    "\"\"\"\n",
    "Define a set of English stopwords using the NLTK library.\n",
    "\"\"\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_top_words(data, sentiment, top_n=10):\n",
    "    \"\"\"\n",
    "    Retrieves the top 'n' words for a given sentiment, excluding stopwords.\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame containing the comments and their associated sentiments.\n",
    "        sentiment (mixed): The sentiment category to filter the comments.\n",
    "        top_n (int): Number of top words to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the most common words for the specified sentiment, excluding stopwords.\n",
    "    \"\"\"\n",
    "    subset = data[data['sentiment'] == sentiment]\n",
    "    words = \" \".join(subset['comment']).split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return [word for word, count in Counter(filtered_words).most_common(top_n)]\n",
    "\n",
    "\"\"\"\n",
    "Prepare and collect the top words for each unique sentiment in the dataset for further analysis.\n",
    "\"\"\"\n",
    "sentiments = data['sentiment'].unique()\n",
    "top_words_by_sentiment = {sent: get_top_words(data, sent) for sent in sentiments}\n",
    "\n",
    "\"\"\"\n",
    "Calculate and compile data concerning the frequency of each top word across all sentiments.\n",
    "\"\"\"\n",
    "rows = []\n",
    "for sentiment, top_words in top_words_by_sentiment.items():\n",
    "    for word in top_words:\n",
    "        for sent in sentiments:\n",
    "            subset = data[data['sentiment'] == sent]\n",
    "            count = sum(subset['comment'].str.split().apply(lambda x: x.count(word)))\n",
    "            rows.append({'Word': word, 'Sentiment': sent, 'Frequency': count})\n",
    "\n",
    "\"\"\"\n",
    "Convert the compiled data into a DataFrame for visualization purposes.\n",
    "\"\"\"\n",
    "plot_data = pd.DataFrame(rows)\n",
    "\n",
    "def create_plot(plot_data, focus_sentiment):\n",
    "    \"\"\"\n",
    "    Generates a bar plot for word frequencies focused on a specific sentiment.\n",
    "    Args:\n",
    "        plot_data (DataFrame): DataFrame containing the words, their frequencies, and sentiments.\n",
    "        focus_sentiment (mixed): The sentiment to focus on for the plot.\n",
    "\n",
    "    Displays:\n",
    "        A bar plot visualizing the frequency of words focused on the specified sentiment.\n",
    "    \"\"\"\n",
    "    focused_words = top_words_by_sentiment[focus_sentiment]\n",
    "    focused_plot_data = plot_data[plot_data['Word'].isin(focused_words)]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Word', y='Frequency', hue='Sentiment', data=focused_plot_data, palette='viridis')\n",
    "    plt.title(f'Word Frequencies Focused on Sentiment {focus_sentiment} (Excluding NLTK Stopwords)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Generate and display plots for each sentiment represented in the data.\n",
    "\"\"\"\n",
    "for sent in sentiments:\n",
    "    create_plot(plot_data, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os gráficos visualizam a frequência de palavras agrupadas por sentimentos negativo, neutro e positivo, com foco em termos que excluem stopwords da NLTK. A palavra \"Uber\" é preeminente em todos os sentimentos, destacando-se especialmente nos comentários negativos e neutros, sugerindo sua relevância frequente nas discussões. Termos como \"leak\" e \"secretly\" nos negativos indicam tópicos de críticas ou controvérsias. Em sentimentos neutros, palavras como \"driver\" e \"time\" aparecem, refletindo discussões mais neutras ou informativas. Nos positivos, além de \"Uber\", \"driver\" também é frequente, apontando para comentários favoráveis ou positivos sobre o serviço. Este padrão de palavras ajuda a identificar os principais temas discutidos e o tom geral dos comentários em diferentes sentimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess the text by converting all comments to lowercase, removing punctuation and digits,\n",
    "and calculating the word count for each comment.\n",
    "\"\"\"\n",
    "data['comment'] = data['comment'].str.lower().str.replace('[^\\w\\s]', '', regex=True).str.replace('\\d+', '', regex=True)\n",
    "data['comment_length'] = data['comment'].apply(lambda x: len(x.split()))\n",
    "\n",
    "\"\"\"\n",
    "Calculate the length of each comment in characters.\n",
    "\"\"\"\n",
    "data['character_length'] = data['comment'].apply(len)\n",
    "\n",
    "\"\"\"\n",
    "Visualize the distribution of comment lengths in words across different sentiments using a boxplot.\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='sentiment', y='comment_length', data=data)\n",
    "plt.title('Comment Length Distribution by Sentiment')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Visualize the distribution of comment lengths in words across different sentiments using a scatter plot,\n",
    "which is useful for observing the spread of data points.\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.stripplot(x='sentiment', y='comment_length', data=data, jitter=True, alpha=0.3)\n",
    "plt.title('Comment Length Scatter by Sentiment')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Visualize the distribution of character lengths in comments across different sentiments using a bar plot.\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='sentiment', y='character_length', data=data, ci=None)  # ci=None removes the error bars\n",
    "plt.title('Character Length Distribution by Sentiment')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Characters')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Visualize the distribution of character lengths in comments across different sentiments using a scatter plot,\n",
    "providing a granular view of the distribution.\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.stripplot(x='sentiment', y='character_length', data=data, jitter=True, alpha=0.3)\n",
    "plt.title('Character Length Scatter by Sentiment')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Characters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de Comprimento dos Comentários por Sentimento (Palavras):\n",
    "Os gráficos relacionados ao comprimento dos comentários em palavras mostram uma distribuição variada de comprimentos através dos diferentes sentimentos. Observando o boxplot, os comentários negativos tendem a ser mais curtos, concentrando-se em torno de um número menor de palavras, enquanto os comentários positivos são tipicamente mais longos, com uma faixa mais ampla de variação no comprimento. Isso pode indicar que usuários tendem a elaborar mais quando expressam satisfação ou elogios. O scatter plot reforça essa observação, mostrando uma maior dispersão nos comentários positivos, indicando variações substanciais no comprimento, enquanto os negativos e neutros apresentam uma aglomeração mais consistente e compacta de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de Comprimento dos Comentários por Sentimento (Caracteres):\n",
    "Quanto ao comprimento dos comentários em caracteres, a análise reflete padrões similares aos observados com o comprimento em palavras. O bar plot mostra que comentários com sentimentos positivos possuem, em média, mais caracteres, o que é consistente com o padrão de maior extensão observado na análise por palavras. Comentários negativos e neutros apresentam menor extensão média de caracteres. No scatter plot de caracteres, a distribuição por sentimentos também espelha essa tendência, com os comentários positivos mostrando maior dispersão, refletindo uma gama mais ampla de extensões de comentário, do breve ao detalhado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
