{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiente de Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo variáveis do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "isAtGoogleColab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (70.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras) (4.12.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\inteli\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inteli\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting google-colab\n",
      "  Using cached google-colab-1.0.0.tar.gz (72 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-auth~=1.4.0 (from google-colab)\n",
      "  Using cached google_auth-1.4.2-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting ipykernel~=4.6.0 (from google-colab)\n",
      "  Using cached ipykernel-4.6.1-py3-none-any.whl.metadata (981 bytes)\n",
      "Collecting ipython~=5.5.0 (from google-colab)\n",
      "  Using cached ipython-5.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting notebook~=5.2.0 (from google-colab)\n",
      "  Using cached notebook-5.2.2-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting six~=1.12.0 (from google-colab)\n",
      "  Using cached six-1.12.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pandas~=0.24.0 (from google-colab)\n",
      "  Using cached pandas-0.24.2.tar.gz (11.8 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [18 lines of output]\n",
      "      C:\\Users\\Inteli\\AppData\\Local\\Temp\\pip-install-mc87wfd3\\pandas_9fc81e8ba8ed47e0b5d760e668eb818c\\setup.py:12: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "        import pkg_resources\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\Inteli\\AppData\\Local\\Temp\\pip-install-mc87wfd3\\pandas_9fc81e8ba8ed47e0b5d760e668eb818c\\setup.py\", line 732, in <module>\n",
      "          version=versioneer.get_version(),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Inteli\\AppData\\Local\\Temp\\pip-install-mc87wfd3\\pandas_9fc81e8ba8ed47e0b5d760e668eb818c\\versioneer.py\", line 1409, in get_version\n",
      "          return get_versions()[\"version\"]\n",
      "                 ^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Inteli\\AppData\\Local\\Temp\\pip-install-mc87wfd3\\pandas_9fc81e8ba8ed47e0b5d760e668eb818c\\versioneer.py\", line 1343, in get_versions\n",
      "          cfg = get_config_from_root(root)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Inteli\\AppData\\Local\\Temp\\pip-install-mc87wfd3\\pandas_9fc81e8ba8ed47e0b5d760e668eb818c\\versioneer.py\", line 399, in get_config_from_root\n",
      "          parser = configparser.SafeConfigParser()\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      AttributeError: module 'configparser' has no attribute 'SafeConfigParser'. Did you mean: 'RawConfigParser'?\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n",
    "%pip install scikit-learn\n",
    "%pip install keras\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install google-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixando dados do spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download('pt_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if isAtGoogleColab:\n",
    "    df = pd.read_csv('/content/processed_classification-labeled.csv', delimiter=',', encoding='latin1')\n",
    "else:\n",
    "    df = pd.read_csv('../data/processed_classification-labeled.csv', delimiter=',', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A \"Bag of Words\" (BoW) é uma técnica simples, mas amplamente utilizada em processamento de linguagem natural (PLN) e mineração de texto. Essa abordagem transforma palavras em números, permitindo que os computadores compreendam e analisem textos de maneira conveniente. \n",
    "\n",
    "#### Ao aplicar a técnica BoW, o texto é tratado como um conjunto não ordenado de palavras, desconsiderando a estrutura gramatical e a sequência das palavras. Portanto, a BoW simplifica o texto para análise, fornecendo uma representação numérica que permite aos computadores processar e extrair informações dos dados textuais de forma eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando usando o CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, identificamos os dados separados em colunas no csv entre tokenizados (X) e classificações de sentimentos (y). Em seguida, dividimos esses conjuntos de dados em conjuntos de treino e teste. E utilizamos o CountVectorizer do scikit-learn para vetorizar os dados, transformando os tokens em uma representação numérica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados entre as colunas de dados tokenizados para vetorização (X) e a classificação do sentimento (y)\n",
    "X = df['pos_tokens']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Agrupar os dados préviamente divididos em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vetorizar os dados com o CountVectorizer do sklearn\n",
    "vectorizer_count = CountVectorizer()\n",
    "X_train_count = vectorizer_count.fit_transform(X_train)\n",
    "X_test_count = vectorizer_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando usando o TfidVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vetorizaremos utilizando o TidfVectorizer. Igualmento a etapa anterior, identificamos as colunas de dados necessárias para treino e teste, e então fazemos essa divisão. A etapa seguinte envolve a vetorização dos dados usando o TfidfVectorizer, uma técnica que atribui pesos às palavras com base em sua frequência nos documentos e na raridade global, transformando-os em números também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados entre as colunas de dados tokenizados para vetorização (X) e a classificação do sentimento (y)\n",
    "X = df['pos_tokens']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Agrupar os dados préviamente divididos em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vetorização com TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de Vetorização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caminho do arquivo\n",
    "file_path = './data/processed_classification-labeled.csv'  # Ajuste conforme necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>links</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pos_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>that, my friend, is why the mighty swift radio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['friend', 'mighty', 'swift', 'radio', 'car', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>spent 20 minutes in an uber listening to what ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['spend', '20', 'minute', 'uber', 'listening',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>via the guardian  guardian front page, monday ...</td>\n",
       "      <td>['https://t.co/hjsUSc6AVZ']</td>\n",
       "      <td>-1</td>\n",
       "      <td>['guardian', 'guardian', 'front', 'page', 'mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>my real job is being my girlfriends personal u...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['real', 'job', 'girlfriend', 'personal', 'ube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>i had a bad drive . i want my refund</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "      <td>['have', 'bad', 'drive', 'want', 'refund']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment  \\\n",
       "0   1  that, my friend, is why the mighty swift radio...   \n",
       "1   2  spent 20 minutes in an uber listening to what ...   \n",
       "2   3  via the guardian  guardian front page, monday ...   \n",
       "3   4  my real job is being my girlfriends personal u...   \n",
       "4   5               i had a bad drive . i want my refund   \n",
       "\n",
       "                         links  sentiment  \\\n",
       "0                           []          0   \n",
       "1                           []          0   \n",
       "2  ['https://t.co/hjsUSc6AVZ']         -1   \n",
       "3                           []          0   \n",
       "4                           []         -1   \n",
       "\n",
       "                                          pos_tokens  \n",
       "0  ['friend', 'mighty', 'swift', 'radio', 'car', ...  \n",
       "1  ['spend', '20', 'minute', 'uber', 'listening',...  \n",
       "2  ['guardian', 'guardian', 'front', 'page', 'mon...  \n",
       "3  ['real', 'job', 'girlfriend', 'personal', 'ube...  \n",
       "4         ['have', 'bad', 'drive', 'want', 'refund']  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1992703751.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def funcao_vetorizer_bow(df, \"pos_tokens\"):\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def funcao_vetorizer_bow(df, pos_tokens):\n",
    "    # combina todos os tokens em uma única string para cada linha\n",
    "    frases = [' '.join(tokens) for tokens in df[pos_tokens]]\n",
    "            # TO COM PROBLEMA NESSA PARTE DOS 'POS_TOKENS'\n",
    "    \n",
    "    # cria o vetorizador\n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    # transforma os dados\n",
    "    X = vectorizer.fit_transform(frases)\n",
    "    \n",
    "    # converte a matriz para um DataFrame\n",
    "    bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Retorna o novo DataFrame\n",
    "    return bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Aplicar a função ao DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bow_df \u001b[38;5;241m=\u001b[39m funcao_vetorizer_bow(df, \u001b[43mpos_tokens\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pos_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# Aplicar a função ao DataFrame\n",
    "bow_df = funcao_vetorizer_bow(df, pos_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserir o Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### A metrificação dos modelos de Bag of Words, como Count Vectorizer e TF-IDF Vectorizer, desempenha um papel fundamental na compreensão e avaliação de sua eficácia na representação de documentos textuais. Esses modelos são amplamente utilizados em tarefas de processamento de linguagem natural, convertendo textos em vetores numéricos para facilitar a análise por algoritmos de aprendizado de máquina. Ao avaliar esses modelos, uma variedade de métricas pode ser empregada, cada uma oferecendo insights específicos sobre diferentes aspectos da representação dos documentos. Entre as métricas comumente utilizadas estão o tamanho do vetor, a frequência do termo, o IDF (Inverse Document Frequency) no TF-IDF Vectorizer, a esparsidade, a distribuição de frequência no Count Vectorizer e a entropia da informação no Count Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho do vetor é uma métrica que indica a dimensão do espaço vetorial resultante da representação dos documentos. Ele é crucial para entender a complexidade e a dimensionalidade dos dados transformados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o tamanho do vocabulário/vetor de cada modelo\n",
    "feature_names_count = vectorizer_count.get_feature_names_out()\n",
    "print(\"Número de termos com CountVectorizer(): \", len(feature_names_count)) \n",
    "feature_names_tfidf = vectorizer_tfidf.get_feature_names_out()\n",
    "print(\"Número de termos com TidfVectorizer(): \", len(feature_names_tfidf)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A frequência do termo refere-se à contagem de ocorrências de palavras individuais nos documentos, o que ajuda a capturar a importância relativa das palavras na representação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar frequência do termo em documentos (DF) de cada modelo\n",
    "print(\"Frequência do termo em documentos (DF) (CountVectorizer):\\n\", X_train_count.sum(axis=0))\n",
    "print(\"Frequência do termo em documentos (DF) (TfidfVectorizer):\\n\", X_train_tfidf.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O IDF, específico do TF-IDF Vectorizer, ajusta a frequência do termo pela raridade da palavra no corpus, destacando termos menos frequentes e potencialmente mais informativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar IDF do TfidVectorizer()\n",
    "print(\"Frequência do documento inversa (IDF) (TfidfVectorizer):\\n\", vectorizer_tfidf.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A esparsidade é uma métrica que indica a proporção de elementos não nulos na matriz de representação dos documentos. Ela é especialmente relevante em grandes conjuntos de dados textuais, onde a maioria das palavras não ocorre em todos os documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar esparsidade dos vetores de cada modelo\n",
    "sparsity_count = 1.0 - np.count_nonzero(X_train_count.toarray()) / float(X_train_count.shape[0] * X_train_count.shape[1])\n",
    "print(\"Esparsidade dos vetores:\", sparsity_count)\n",
    "sparsity_tfidf = 1.0 - np.count_nonzero(X_train_tfidf.toarray()) / float(X_train_tfidf.shape[0] * X_train_tfidf.shape[1])\n",
    "print(\"Esparsidade dos vetores TF-IDF:\", sparsity_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distribuição de frequência no Count Vectorizer é uma medida da dispersão das contagens de palavras nos documentos, oferecendo insights sobre a variabilidade e a heterogeneidade do vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar distribuição de Frequência de Palavras de cada modelo\n",
    "word_frequencies = np.sum(X_train_count.toarray(), axis=0)\n",
    "print(\"Distribuição de Frequência de Palavras:\", word_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, a entropia da informação no Count Vectorizer avalia a incerteza associada à distribuição de frequência das palavras nos documentos, destacando a diversidade e a riqueza do conteúdo textual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar entropia da Informação do CountVectorizer()\n",
    "word_probabilities = word_frequencies / np.sum(word_frequencies)\n",
    "entropy = -np.sum(word_probabilities * np.log2(word_probabilities))\n",
    "print(\"Entropia da Informação:\", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante testar cada métrica em função do modelo específico utilizado, pois cada uma delas oferece perspectivas distintas sobre a qualidade e a adequação da representação dos documentos. Enquanto a distribuição de frequência pode ser facilmente medida no Count Vectorizer devido à natureza das contagens de palavras, o IDF no TF-IDF Vectorizer é mais relevante devido ao seu ajuste pela frequência inversa do documento. Cada métrica desempenha um papel único na análise e na otimização dos modelos de Bag of Words, permitindo uma compreensão abrangente de sua capacidade de representação e de sua utilidade em uma variedade de aplicações de processamento de linguagem natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de medidor BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Esta seção do notebook concentra-se na análise dos resultados obtidos pela metrificação dos modelos testados acima, destacando métricas como tamanho de vetor, frequência de termo, esparsidade e distribuição de frequência de palavras, a fim de determinar qual abordagem é mais adequada para a tarefa de análise de sentimentos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Número de termos com CountVectorizer() e TfidfVectorizer():**\n",
    "   - Ambos os modelos produziram o mesmo número de termos, o que sugere consistência na representação dos corpus em termos de dimensionalidade.\n",
    "\n",
    "2. **Frequência do termo em documentos (DF):**\n",
    "   - No CountVectorizer(), a frequência dos termos é representada como contagens inteiras, o que pode ser útil para identificar a importância absoluta das palavras em um documento.\n",
    "   - No TfidfVectorizer(), a frequência dos termos é normalizada pelo IDF, o que pode ajudar a destacar a importância relativa das palavras no contexto do corpus. Isso pode ser benéfico para identificar palavras que são distintas em diferentes classes de sentimento.\n",
    "\n",
    "3. **Frequência do documento inversa (IDF) (TfidfVectorizer()):**\n",
    "   - O IDF atribui maior peso a termos menos frequentes, o que pode ser valioso na identificação de palavras-chave que são mais discriminativas para diferentes classes de sentimento.\n",
    "\n",
    "4. **Esparsidade dos vetores:**\n",
    "   - A alta esparsidade sugere que a maioria dos termos em um documento não ocorre em todos os documentos, o que é típico em análise de texto. Isso indica que ambos os modelos são capazes de lidar com a diversidade vocabular encontrada em conjuntos de dados textuais extensos.\n",
    "\n",
    "5. **Distribuição de Frequência de Palavras:**\n",
    "   - A distribuição de frequência de palavras nos documentos pode ser útil para identificar termos frequentes e raros em diferentes classes de sentimento.\n",
    "   \n",
    "6. **Entropia da Informação:**\n",
    "   - Uma alta entropia da informação indica uma distribuição mais uniforme de frequências de palavras nos documentos. Isso pode sugerir uma diversidade maior de palavras e uma potencial complexidade na classificação de sentimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nas métricas acima isoladas de qualquer modelagem de aprendizado de máquina, o TfidfVectorizer é a escolha preferencial nesse momento. Isso se deve à sua capacidade de destacar a importância relativa das palavras no contexto do corpus, o que é especialmente relevante para uma análise de sentimento que considera a quantidade/peso das palavras na classificação entre positivo, neutro e negativo.\n",
    "\n",
    "No entanto, é importante ressaltar que a escolha final do modelo deve considerar não apenas as métricas do BoW, mas também o desempenho em tarefas de aprendizado de máquina específicas. Nesse sentido, as métricas do Naive Bayes e da Regressão Linear na próxima seção podem fornecer informações cruciais sobre a eficácia do modelo na tarefa de análise de sentimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos ML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa última parte do notebook, analisaremos as métricas retiradas de dois modelos de ML, o Naive Bayes e a Regressão Linear, com os dois modelos de Bag of Words. Aqui será decidido o modelo final de ambos para essa primeira etapa do projeto. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Naive Bayes é um algoritmo de aprendizado supervisionado baseado no teorema de Bayes, que assume independência condicional entre os recursos (variáveis preditoras). É particularmente popular em aplicações que envolvem texto, como classificação de documentos, análise de sentimento e detecção de spam.\n",
    "\n",
    "Ele calcula as probabilidades condicionais de cada classe dada uma observação usando o teorema de Bayes e a suposição de independência entre os recursos. Em seguida, seleciona a classe com a maior probabilidade condicional como a previsão final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * CountVectorizer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar e treinar o classificador Naive Bayes\n",
    "nb_classifier_count = MultinomialNB()\n",
    "nb_classifier_count.fit(X_train_count, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "nb_y_pred_count = nb_classifier_count.predict(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, nb_y_pred_count)\n",
    "print(\"Acurácia do Naive Bayes com CountVectorizer():\", accuracy)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, nb_y_pred_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As métricas utilizadas para a escolha do modelo foram o precision (precisão), recall (revocação) e f1-score (que é a média das outras duas métricas). Suas escolhas foram feitas baseadas na necessidade do cliente em reconhecer todos os casos negativos mesmo que isso gere falsos negativos. Para mais detalhes a sessão [6.4](#c6.4) apresenta a escolha de métricas mais detalhadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, nb_y_pred_count)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * TdfifVectorizer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar e treinar o classificador Naive Bayes\n",
    "nb_classifier_tfidf = MultinomialNB()\n",
    "nb_classifier_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "nb_y_pred_tfidf = nb_classifier_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, nb_y_pred_tfidf)\n",
    "print(\"Acurácia do Naive Bayes com TfidfVectorizer():\", accuracy)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, nb_y_pred_tfidf, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, nb_y_pred_tfidf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Purples\")\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Regressão Logística é um modelo de aprendizado supervisionado usado para tarefas de classificação binária e multiclasse. Apesar do nome, ela é usada para tarefas de classificação, não para regressão. \n",
    "\n",
    "A Regressão Logística é um modelo linear e é particularmente útil quando a relação entre os recursos e a classe de interesse é aproximadamente linear. Ela é amplamente utilizada em diversas áreas, além disso, a Regressão Logística pode ser estendida para lidar com problemas de classificação multiclasse e para incorporar regularização para evitar overfitting em conjuntos de dados de alta dimensionalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * CountVectorizer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar e treinar o classificador de regressão logística\n",
    "logreg_classifier_count = LogisticRegression()\n",
    "logreg_classifier_count.fit(X_train_count, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "lc_y_pred_count = logreg_classifier_count.predict(X_test_count)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, lc_y_pred_count)\n",
    "print(\"Acurácia da Regressão Logística com CountVectorizer():\", accuracy)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, lc_y_pred_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lc_y_pred_count)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * TdfifVectorizer( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar e treinar o classificador de regressão logística\n",
    "logreg_classifier_tfidf = LogisticRegression()\n",
    "logreg_classifier_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "lc_y_pred_tfidf = logreg_classifier_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, lc_y_pred_tfidf)\n",
    "print(\"Acurácia da Regressão Logística com TfidfVectorizer():\", accuracy)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, lc_y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lc_y_pred_tfidf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Purples\")\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados apresentados, ambos os modelos mostraram desempenhos variados em diferentes classes e vetores de características.\n",
    "\n",
    "Apesar de a Regressão Logística com TfidfVectorizer ter apresentado uma acurácia ligeiramente superior, é importante notar que essa abordagem teve dificuldades em prever corretamente instâncias da classe positiva (1), resultando em um _precision_ de 1.0 para essa classe. Isso indica uma limitação do modelo em aprender padrões relevantes para essa classe específica.\n",
    "\n",
    "Portanto, a melhor opção para essa primeira fase é Regressão Logística com CountVectorizer(). Este modelo mostrou uma acurácia comparável à do modelo com TfidfVectorizer, mas sem o problema de previsões excessivamente otimistas para a classe positiva. Assim, essa combinação parece ser a mais robusta para este conjunto de dados, oferecendo um equilíbrio entre desempenho e generalização."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
